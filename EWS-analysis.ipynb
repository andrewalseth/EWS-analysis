{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enduro World Series (EWS) web scraping and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping\n",
    "This notebook downloads and analyzes the results from the EWS from its inception to current, and we carry out analysis on these results. Like any good data science project, data wrangling takes 80% of the time...\n",
    "\n",
    "First, we begin by downloading results and scraping the files from https://www.enduroworldseries.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import typing_extensions\n",
    "import re\n",
    "import copy\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PyPDF2 import PdfWriter, PdfReader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions to make web scraping more pretty. We're using the `requests` package to to download page information and returning in a cleaned up format using `bs4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_page(url):\n",
    "\theaders = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'}\n",
    "\n",
    "\treq = requests.get(url, headers=headers)\n",
    "\n",
    "\ttry:\n",
    "\t\treq.raise_for_status()\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f'Downloading failed: {e}')\n",
    "\t\n",
    "\treturn bs4.BeautifulSoup(req.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then download the pages for each of the race years for standard EWS race results and EMTB race results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "emtb_result = \"https://www.enduroworldseries.com/races/6/\" \n",
    "ews_result = \"https://www.enduroworldseries.com/races/1/\"\n",
    "\n",
    "emtb_years = [2020, 2021, 2022]\n",
    "ews_years = [2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "list_of_emtb_soup = [download_page(emtb_result + str(year) + '/') for year in emtb_years]\n",
    "\n",
    "list_of_ews_soup = [download_page(ews_result + str(year) + '/') for year in ews_years]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now onto downlading the actual url's which contain the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_links(results_page, result_url, year):\n",
    "\tlinks = results_page.find_all('a', href=True)\n",
    "\tlinks = [link.get('href') for link in links]\n",
    "\n",
    "\trace_list_URL = [result_url[:-9]+str(link_text) for link_text in links if 'results' in link_text]\n",
    "\n",
    "\treturn [(url, url.split('/')[-4]) for url in race_list_URL if str(year) in url] # returns the tuple of the URL and the name of the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_to_emtb_results = [get_result_links(list_of_emtb_soup[i], emtb_result, emtb_years[i]) for i in range(len(emtb_years))]\n",
    "links_to_ews_results = [get_result_links(list_of_ews_soup[i], ews_result, ews_years[i]) for i in range(len(ews_years))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.enduroworldseries.com/race/ews-round-2/SpecializedZermattEWS-E/202048/results/',\n",
       "  'SpecializedZermattEWS-E'),\n",
       " ('https://www.enduroworldseries.com/race/ews-round-1/ZermattEWS-E100/202071/results/',\n",
       "  'ZermattEWS-E100'),\n",
       " ('https://www.enduroworldseries.com/race/ews-round-1/ZermattEWS-E50/202072/results/',\n",
       "  'ZermattEWS-E50'),\n",
       " ('https://www.enduroworldseries.com/race/ews-round-2/VittoriaPietraLigureEWS-E/202049/results/',\n",
       "  'VittoriaPietraLigureEWS-E'),\n",
       " ('https://www.enduroworldseries.com/race/ews-round-2/PietraLigureEWS-E1002020/202073/results/',\n",
       "  'PietraLigureEWS-E1002020'),\n",
       " ('https://www.enduroworldseries.com/race/ews-round-2/PietraLigureEWS-E502020/202074/results/',\n",
       "  'PietraLigureEWS-E502020'),\n",
       " ('https://www.enduroworldseries.com/race/ews-round-0/CANCELEDOlarguesEWS-E/202047/results/',\n",
       "  'CANCELEDOlarguesEWS-E'),\n",
       " ('https://www.enduroworldseries.com/race/ews-round-0/CANCELEDOlarguesEWS-E100/202069/results/',\n",
       "  'CANCELEDOlarguesEWS-E100'),\n",
       " ('https://www.enduroworldseries.com/race/ews-round-0/CANCELEDOlarguesEWS-E50/202070/results/',\n",
       "  'CANCELEDOlarguesEWS-E50'),\n",
       " ('https://www.enduroworldseries.com/race/ews-round-0/CANCELLED-ValbergEWS-E2020/202091/results/',\n",
       "  'CANCELLED-ValbergEWS-E2020')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_to_emtb_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pdf_links(soup):\n",
    "\tHTML_source = soup.find_all('a', href=True)\n",
    "\tsource_links = [(link.get('href'), link) for link in HTML_source]\n",
    "\n",
    "\treturn [(pdf, pdf_link.get_text()) for pdf, pdf_link in source_links if '.pdf' in pdf]\n",
    "\n",
    "def download_pdf(url, folder_path, filename):\n",
    "\treq = requests.get(url)\n",
    "\treq.raise_for_status()\n",
    "\n",
    "\twith open(folder_path + filename, 'wb') as f:\n",
    "\t\tf.write(req.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_downloads(result_links, years, folder_path):\n",
    "\tfor i in range(len(years)):\n",
    "\n",
    "\t\tyear = years[i]\n",
    "\n",
    "\t\tfor race_link, race_name in result_links[i]:\n",
    "\n",
    "\t\t\trace_page = download_page(race_link)\n",
    "\t\t\tresult_pdf = find_pdf_links(race_page)\n",
    "\n",
    "\t\t\tfor pdf_link, pdf_text in result_pdf:\n",
    "\n",
    "\t\t\t\tfilename = str(year)+ '_' + race_name + '_' + pdf_text.replace(' ', '_') + '.pdf'\n",
    "\t\t\t\tdownload_pdf(pdf_link, folder_path, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pdf_downloads(links_to_emtb_results, emtb_years, 'emtb_results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pdf_downloads(links_to_ews_results, ews_years, 'ews_results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"raw_pdf/test3.pdf\")\n",
    "pages = [page.extract_text().split('\\n') for page in reader.pages] # newline separates lines on all pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the PDF\n",
    "Now that we have read in the various PDF, we need to pull the data out into a useable format. PDF's are tricky beasts, so we're going to rely on the `PyPDF2` package to take these data in. Unfortunately, these PDF are not set up as tables (otherwise this would be a trivial import using the `camelot` package), so we need to use a bunch of regular expressions to extract the desired data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various regular expressions to extract data from text of results PDF\n",
    "stage_numbers_regex = re.compile(r'Stage \\d')\t\t\t\t\t# recognizes stage numbers in headers of PDF\n",
    "position_plate_name_regex = re.compile(r'\\d+\\s\\d+\\s[^a-z]+[a-z]+\\s')\t\t# finds rider position and name from individuals\n",
    "dnf_dns_plate_name_regex = re.compile(r'(DNF|DNS|DSQ)\\s\\d+\\s[^a-z]+[a-z]+\\s')\t# finds DNF/DNS rider information \n",
    "stage_position_regex = re.compile(r'\\d:\\d\\d:\\d\\d\\.\\d\\d \\d+') \t\t\t# recognizes the a stage with its position\n",
    "stage_time_regex = re.compile(r'(\\d:\\d\\d:\\d\\d\\.\\d\\d)') \t\t\t\t# recognizes each stage time (assumes all stages  <10 hours)\n",
    "gap_regex = re.compile(r'\\+\\d:\\d\\d:\\d\\d\\.\\d\\d') \t\t\t\t# determines gap from overall leader \n",
    "penalty_regex = re.compile(r'\\d:\\d\\d:\\d\\d\\.\\d\\d\\s+\\d:\\d\\d:\\d\\d\\.\\d\\d') \t\t# penalty values occur before overall stage results\n",
    "rider_id_regex = re.compile(r'\\w{3}\\.[\\d\\w\\s]+\\.[\\d\\w]+') \t\t\t# gets rider ID from results\n",
    "lastname_regex = re.compile(r'\\s[^a-z0-9]+')\t\t\t\t\t# recognizes lastname - located between plate and firstname, no lowercase or numbers\n",
    "firstname_regex = re.compile(r'[A-Z][a-z]+')\t\t\t\t\t# recognizes firstname - first capital letter then lowercase \n",
    "position_plate_regex = re.compile(r'\\d+\\s\\d+')\t\t\t\t\t# recognizes the position and plate\n",
    "dnf_dns_plate_regex = re.compile(r'(DNF|DNS|DSQ)\\s\\d+')\t\t\t\t# recognizes DNF/DNS/DSQ along with plate\n",
    "\n",
    "#TODO need better regex for firstname/lastname - see G.T. CLYNE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is ugly, but this is the function which reads the results PDF files and converts to csv. We convert to csv for easy storage and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ews_pdf_to_csv(pdf_location, csv_location='csv_output/'):\n",
    "\n",
    "\t# read in PDF and convert each page to list of strings\n",
    "\treader = PdfReader(pdf_location)\n",
    "\tpages = [page.extract_text().split('\\n') for page in reader.pages] # newline separates lines on all pages\n",
    "\n",
    "\tpdf_header = pages[0][:5]\n",
    "\tcolumns = pdf_header[0] + pdf_header[1] # first two lines are the column names for the file\n",
    "\n",
    "\t# race information\n",
    "\tnum_stages = len(stage_numbers_regex.findall(columns)) # store the total number of stages based upon header\n",
    "\trace_date = pdf_header[3]\n",
    "\trace_location = pdf_header[2]\n",
    "\trace_type = 'standard'\n",
    "\n",
    "\trace_info = [race_date, race_location, race_type]\n",
    "\n",
    "\theader_race_info = ['date', 'race_location', 'race_type']\n",
    "\theader_rider_info = ['rider_category','rider_plate', 'rider_lastname', 'rider_firstname', 'rider_id', 'rider_final_position',\n",
    "\t\t'rider_penalties' , 'rider_final_time' , 'gap_from_first']\n",
    "\theader_rider_stage_results = ['stage_'+str(i)+'_time' for i in range(1,num_stages+1)] + ['stage_'+str(i)+'_pos' for i in range(1,num_stages+1)]\n",
    "\t# df_list = [['rider_num', 'rider_name', 'rider_id', 'rider_final_position' + 'rider_final_time'] + ['stage_'+str(i)+'time']]\n",
    "\n",
    "\trace_header_info = [header_race_info + header_rider_info + header_rider_stage_results]\n",
    "\n",
    "\tall_results = race_header_info\n",
    "\n",
    "\n",
    "\tfor page in pages:\n",
    "\n",
    "\t\tis_results_page = pdf_header[0] == page[0] # checks if the first line of the page matches the header\n",
    "\t\t\n",
    "\t\tif is_results_page:\n",
    "\t\t\ti = 5 # start after header\n",
    "\t\t\trider_catagory = ''\n",
    "\n",
    "\t\t\t# iterate over all lines except final (which contains metadata)\n",
    "\t\t\twhile i < len(page) - 1:\n",
    "\n",
    "\t\t\t\tppnr = position_plate_name_regex.search(page[i])\n",
    "\t\t\t\tddr = dnf_dns_plate_name_regex.search(page[i])\n",
    "\n",
    "\t\t\t\tif ppnr or ddr: # check if line contains rider information \n",
    "\t\t\t\t\tresult = copy.deepcopy(race_info)\n",
    "\n",
    "\t\t\t\t\tline1 = page[i]\n",
    "\t\t\t\t\ti += 1\n",
    "\t\t\t\t\tline2 = page[i]\n",
    "\n",
    "\t\t\t\t\tfix = stage_time_regex.sub(r' \\1', line1+line2) # adds space before each stage time - used to fix issue with formatting of underlines\n",
    "\t\t\t\t\tfix = fix.replace('+ ', '+') # removes space before gap time\n",
    "\n",
    "\t\t\t\t\tif ppnr:\n",
    "\t\t\t\t\t\tinfo = ppnr.group()\n",
    "\t\t\t\t\t\tppr = position_plate_regex.search(info)\n",
    "\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tinfo = ddr.group()\n",
    "\t\t\t\t\t\tppr = dnf_dns_plate_regex.search(info)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tposition, plate = ppr.group().split(' ')\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tlastname = lastname_regex.search(info).group()\n",
    "\t\t\t\t\tlastname = lastname[1:-2]\n",
    "\t\t\t\t\tfirstname = firstname_regex.search(info).group()\n",
    "\n",
    "\t\t\t\t\tspr = stage_position_regex.findall(fix)\n",
    "\t\t\t\t\tspr = [s.split(' ') for s in spr]\t\n",
    "\n",
    "\t\t\t\t\trir = rider_id_regex.search(fix)\n",
    "\t\t\t\t\tpr = penalty_regex.search(line1)\n",
    "\t\t\t\t\tgr = gap_regex.search(fix)\n",
    "\t\t\t\t\tst = stage_time_regex.findall(line1)\n",
    "\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t\trider_num = None\n",
    "\t\t\t\t\tif rir:\n",
    "\t\t\t\t\t\trider_num = rir.group()\n",
    "\n",
    "\n",
    "\t\t\t\t\tpenalty_time = None\n",
    "\t\t\t\t\tif pr:\n",
    "\t\t\t\t\t\tpenalty_time = pr.group().split(' ')[0]\n",
    "\n",
    "\t\t\t\t\tresult += [rider_category, plate, lastname, firstname, rider_num, position, penalty_time]\n",
    "\n",
    "\t\t\t\t\tif ppnr:\n",
    "\t\t\t\t\t\tif gr:\n",
    "\t\t\t\t\t\t\tfinal_time = st[-2]\n",
    "\t\t\t\t\t\t\tgap \t   = st[-1]\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tfinal_time = st[-1]\n",
    "\t\t\t\t\t\t\tgap = '0:00:00.00'\n",
    "\n",
    "\t\t\t\t\t\tresult += [final_time, gap]\n",
    "\t\t\t\t\t\tresult += [stage_time for stage_time, stage_pos in spr]\n",
    "\t\t\t\t\t\tresult += [stage_pos for stage_time, stage_pos in spr]\n",
    "\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tresult += [None, None] # no gap or final time for DNF/DNS/DSQ\n",
    "\t\t\t\t\t\tstage_diff = num_stages - len(spr) # calculate how many stages were not completed\n",
    "\n",
    "\t\t\t\t\t\tresult += [stage_time for stage_time, stage_pos in spr] + [None for _ in range(stage_diff)]\n",
    "\t\t\t\t\t\tresult += [stage_pos for stage_time, stage_pos in spr] + [None for _ in range(stage_diff)]\n",
    "\n",
    "\t\t\t\t\tall_results.append(result)\n",
    "\t\t\t\t\ti += 1\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "\t\t\t\telse:\t# otherwise, this is category information for the following riders\n",
    "\t\t\t\t\trider_category = page[i]\n",
    "\t\t\t\t\ti += 1\n",
    "\t\n",
    "\tpdf_filename = os.path.split(pdf_location)[1][:-4]\n",
    "\n",
    "\twith open(csv_location + pdf_filename + '.csv', 'w', newline='') as cw:\n",
    "\t\twriter = csv.writer(cw)\n",
    "\t\tfor row in all_results:\n",
    "\t\t\twriter.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ews_pdf_to_csv(\"raw_pdf/test3.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('raw_pdf', 'test3.pdf')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.split(\"raw_pdf/test3.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv_output/test3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[-1][0] == pdf_header[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_results[0]) == len(all_results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['March 24 - 25, 2018',\n",
       " 'Lo Barnechea, Chile',\n",
       " 'standard',\n",
       " 'MEN',\n",
       " '1',\n",
       " 'HILL',\n",
       " 'Sam',\n",
       " 'AUS.1985.21775',\n",
       " '1',\n",
       " None,\n",
       " '0:55:02.18',\n",
       " '0:00:00.00',\n",
       " '0:05:12.25',\n",
       " '0:18:07.96',\n",
       " '0:05:26.70',\n",
       " '0:09:55.25',\n",
       " '0:04:07.43',\n",
       " '0:12:12.59',\n",
       " '2',\n",
       " '1',\n",
       " '2',\n",
       " '2',\n",
       " '1',\n",
       " '1']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page2 = page2text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pos Plate Name Nat Stage 1 Pos Stage 2 Pos Stage 3 Pos Stage 4 Pos Penalties Time Gap',\n",
       " '   Team EMBA Stage 5 Pos Stage 6 Pos Stage 7 PosCrankworx Rotorua Giant Toa Enduro',\n",
       " 'Rotorua, New Zealand',\n",
       " 'March 26, 2017',\n",
       " 'RESULTS OVERALL',\n",
       " 'MEN | Master 40+',\n",
       " '17 724 TAGUE Alex 0:04:08.14 10 0:06:10.11 9 0:07:12.94 27 0:07:44.67 11 0:50:45.24 +0:11:11.53',\n",
       " ' NZL.TAGA.1976 0:11:52.82 21 0:06:53.99 24 0:06:42.57 14',\n",
       " '18 729 DAWSON Guy 0:04:43.30 21 0:07:14.50 24 0:06:32.52 20 0:09:08.07 22 0:51:33.69 +0:11:59.98',\n",
       " ' 0:10:44.76 15 0:06:12.16 17 0:06:58.38 18',\n",
       " '19 730 SCHAUT Duncan 0:05:04.41 25 0:07:12.12 23 0:06:01.95 16 0:08:48.45 21 0:51:37.63 +0:12:03.92',\n",
       " ' 0:10:54.67 17 0:06:29.37 20 0:07:06.66 19',\n",
       " '20 717 PIRES Armando 0:04:40.32 20 0:07:00.89 20 0:06:28.87 18 0:08:35.49 20 0:51:50.61 +0:12:16.90',\n",
       " ' BRA.PIRA.1974 0:11:32.84 20 0:06:22.62 18 0:07:09.58 21',\n",
       " '21 728 SPRAGUE Steve 0:04:48.68 23 0:07:02.20 21 0:06:47.25 23 0:09:09.64 23 0:54:27.44 +0:14:53.73',\n",
       " ' 0:12:54.08 23 0:06:38.83 21 0:07:06.76 20',\n",
       " '22 709 MIER Richard 0:04:58.22 24 0:07:34.93 27 0:06:35.76 22 0:09:38.70 25 0:55:25.27 +0:15:51.56',\n",
       " ' GBR.MIER.1972 0:12:48.54 22 0:06:26.57 19 0:07:22.55 23',\n",
       " '23 718 JAGGY Raphael 0:05:10.61 26 0:07:14.98 25 0:06:50.18 24 0:09:24.28 24 0:57:51.66 +0:18:17.95',\n",
       " ' SUI.JAGR.1971 0:15:08.10 25 0:06:42.23 22 0:07:21.28 22',\n",
       " '24 721 NOBLE Andrew 0:05:18.85 28 0:07:57.14 29 0:08:17.04 28 0:11:11.19 26 1:06:23.22 +0:26:49.51',\n",
       " ' AUS.NOBA.1974 0:18:47.78 26 0:06:53.07 23 0:07:58.15 24',\n",
       " 'DNF 726 EGGLESTON Erin 0:04:16.37 13 0:06:22.97 12 0:05:15.12 9 0:07:43.91 10',\n",
       " ' 0:09:16.98 8',\n",
       " 'DNF 727 SPANBROEK Paul 0:04:44.49 22 0:06:40.94 16 0:06:55.67 26 0:08:16.65 18',\n",
       " ' 0:13:48.95 24',\n",
       " 'DNF 716 GRAHAM Kel 0:06:38.88 31 0:08:19.28 30 0:09:37.69 30 0:17:43.24 27',\n",
       " ' AUS.GRAK.1969',\n",
       " 'DNF 713 BADDILEY Jono 0:04:17.29 14 0:06:42.49 17 0:06:02.40 17',\n",
       " ' NZL.BADJ.1971',\n",
       " 'DNF 732 EASTMAN Lance 0:05:12.76 27 0:07:23.47 26 0:06:50.62 25',\n",
       " 'DNF 733 STILWELL Gordon 0:05:23.90 29 0:07:46.87 28 0:08:29.52 29',\n",
       " 'DNF 715 ADAMS Geoff 0:07:09.57 32 0:09:44.06 32 0:14:51.18 31',\n",
       " ' AUS.ADAG.1966',\n",
       " 'DNF 714 SHEPHEARD Jason 0:05:53.26 30 0:08:41.67 31 0:22:17.25 32',\n",
       " ' AUS.SHEJ.1972',\n",
       " '12/20 created on 02.05.2017 16:45:57 Timing and results by']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note the issues with the underlines \n",
    "pages[11].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line1 = '4 13 HILL Sam 0:03:28.58 22 0:05:44.14 28 0:04:55.69 190:06:44.10 1 0:37:40.33 +0:00:08.61'\n",
    "line2 = '  Chain Reaction Cycles Mavic AUS.HILS.1985 0:07:19.73 7 0:04:17.81 20:05:10.28 1'\n",
    "\n",
    "line1 = '147 122 DA SILVA Goncalo 0:04:11.38 125 0:09:38.38 157 0:07:50.37 154 0:11:31.81 153 0:01:00.00 1:10:34.72 +0:33:03.00'\n",
    "line2 = ' POR.DA G.1987 0:19:28.41 147 0:08:13.09 148 0:08:41.28 148'\n",
    "\n",
    "fix = stage_time_regex.sub(r' \\1', line1+line2) # adds space before each stage time - used to fix issue with formatting of underlines\n",
    "fix = fix.replace('+ ', '+') # removes space before gap time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'147 122 DA SILVA Goncalo  0:04:11.38 125  0:09:38.38 157  0:07:50.37 154  0:11:31.81 153  0:01:00.00  1:10:34.72 +0:33:03.00 POR.DA G.1987  0:19:28.41 147  0:08:13.09 148  0:08:41.28 148'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppnr = position_plate_name_regex.search(fix)\n",
    "spr = stage_position_regex.findall(fix)\n",
    "rir = rider_id_regex.search(fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = penalty_regex.search(fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:01:00.00  1:10:34.72'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'147 122 DA SILVA Goncalo '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppnr.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spr = [s.split(' ') for s in spr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0:04:11.38', '125'],\n",
       " ['0:09:38.38', '157'],\n",
       " ['0:07:50.37', '154'],\n",
       " ['0:11:31.81', '153'],\n",
       " ['0:19:28.41', '147'],\n",
       " ['0:08:13.09', '148'],\n",
       " ['0:08:41.28', '148']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POR.DA G.1987'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rir.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95fc6b46201b03e388ee93255aacead15bb4c5a805a1325bd67fb6d36cada86c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
