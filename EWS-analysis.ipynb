{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enduro World Series (EWS) web scraping and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, what is enduro? Basically, it's downhill mountain biking where you have to pedal your way to each stage. Racers are timed on the downhill portion, and then have to pedal their way to the next stage (instead of taking a chair lift, etc.). It looks like:\n",
    "\n",
    "![https://images.app.goo.gl/64AV4ZtHASXin8Ru9](img/muddy_enduro.gif)\n",
    "\n",
    "But also a long day in the saddle. For an example, here's the summary of a race on Strava of a pro enduro racer [Jesse Melamed](https://www.strava.com/activities/7260508291) who took 2nd place (by less than half a second to first!). On the clock, his time was 03:00.67 - wheras the total pedaling time was over three and a half hours!\n",
    "\n",
    "![](img/example_ews.png)\n",
    "\n",
    "Enduro racing at the world stage happens in the Enduro World Series, where the best of the best earn points by winning stages and races. At the end of the season a victor is crowned based on the number of points earned. We're going to take a look at the results in these races and look for trends that identify the types of performances that can crown a winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather the data - web scraping\n",
    "The following cells of this notebook download the results from the EWS for 2022. We only use the ! Like any good data science project, data wrangling takes 80% of the time... in this case, it was much more. I initally attempted to download the PDF's from multiple prior years, but the attempt to build regular expressions was just not worth the time. Looking into the newest data allowed me to pull data in JSON format and much more easily transform the data into a usable format.\n",
    "\n",
    "First, we begin by downloading results and scraping the files from https://www.enduroworldseries.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import typing_extensions\n",
    "import re\n",
    "import copy\n",
    "import csv\n",
    "import os\n",
    "import traceback\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PyPDF2 import PdfWriter, PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions to make web scraping more pretty. We're using the `requests` package to make requests to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo find out the file structure for races - it seems that each result is sorted by class in the form //race_results/class/class#\n",
    "#todo determine the classes and class numbers present\n",
    "\n",
    "import requests\n",
    "\n",
    "base_url = \"https://a23ea854a37f.arangodb.cloud:8529/_db/EWSDB/api_production//\"\n",
    "\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Authorization\": \"Basic QVBJX0VXUzpJRG9BUElUaGluZ3NGb3JQZW9wbGUuITI=\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"DNT\": \"1\",\n",
    "    \"Origin\": \"https://www.enduroworldseries.com\",\n",
    "    \"Referer\": \"https://www.enduroworldseries.com/\",\n",
    "    \"Sec-Fetch-Dest\": \"empty\",\n",
    "    \"Sec-Fetch-Mode\": \"cors\",\n",
    "    \"Sec-Fetch-Site\": \"cross-site\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\",\n",
    "    \"sec-ch-ua-mobile\": \"?0\",\n",
    "    \"sec-ch-ua-platform\": \"macOS\",\n",
    "    \"sec-gpc\": \"1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_json_dict(url, payload=payload, headers=headers, save=False, folder=\"\", filename=\"\", year=\"2022\"):\n",
    "\tresults = requests.request(\"GET\", url, data=payload, headers=headers)\n",
    "\t\n",
    "\tif save:\n",
    "\t\twith open(year+folder+filename+\".json\", 'w+') as f:\n",
    "\t\t\tjson.dump(results, f)\n",
    "\n",
    "\treturn json.loads(results.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_json_string(url, payload=payload, headers=headers, save=False, folder=\"\", filename=\"\", year=\"2022\"):\n",
    "\tresults = requests.request(\"GET\", url, data=payload, headers=headers)\n",
    "\t\n",
    "\tif save:\n",
    "\t\twith open(year+folder+filename+\".json\", 'w+') as f:\n",
    "\t\t\tjson.dump(results, f)\n",
    "\n",
    "\treturn results.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_races_2022 = \"race_names/2022\"\n",
    "race_information = url_to_json_dict(base_url+url_races_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_names_2022 = [race['description'] for race in race_information]\n",
    "\n",
    "race_url_strings_2022 = {race:race.replace(' ', '%20') for race in race_names_2022}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_classes_2022 = {race:url_to_json_dict(base_url+\"race_classes/2022/\"+race_string) for race, race_string in race_url_strings_2022.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual rider query: race_results/rider/[rider class]/[rider #]\n",
    "\n",
    "rider_result_test = url_to_json_dict(base_url+\"race_results/rider/80467121/22930\")\n",
    "\n",
    "rider_result_test = rider_result_test[0]\n",
    "\n",
    "results_format = ['time', 'stage_result', 'cumulative_result', 'cumulative_behind', 'overall_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rider_result_test[0]['stage'][:7].lower().replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom unpacking of data - convert data to columns\n",
    "def unpack_stage_results(rider_results, rider_id, results_format=results_format, save=False):\n",
    "\ti = 1\n",
    "\toffset = 0\n",
    "\theader = []\n",
    "\tresults = []\n",
    "\twhile i < len(rider_results) + 1:\n",
    "\t\tstage_data = rider_results[i-1]['stage'] # trims results from format of 'Stage 1PRO' to 'Stage 1' in case of pro/queen stage\n",
    "\t\tif len(stage_data) > 7:\n",
    "\t\t\tstage_data = stage_data[:7]\n",
    "\t\tstage_info = stage_data.lower().replace(\" \", \"_\") # modifies results from format of 'Stage 1' to 'stage_1'\n",
    "\t\tstage_info = stage_info + \"_\"\n",
    "\t\tfor result in results_format:\n",
    "\t\t\theader.append(stage_info + result)\n",
    "\t\t\tresults.append(rider_results[i-1][result])\n",
    "\n",
    "\t\ti +=1\n",
    "\n",
    "\treturn ['rider_id']+header, [rider_id]+results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_class = \"80467121\"\n",
    "# TODO adjust for riders not having results in all categories\n",
    "\n",
    "#for race in race_classes_2022['EWS Burke']:\n",
    "\n",
    "results_dict = dict()\n",
    "\n",
    "for race_name in race_classes_2022.keys():\n",
    "\n",
    "\tfor race_class in race_classes_2022[race_name]:\n",
    "\t#for race_class in [{'name': 'EWS80 | MEN', '_key': '80470280'},{'name': 'MEN', '_key': '80467139'}]:\n",
    "\n",
    "\t\t# race information for a specific race class\n",
    "\t\trace_class_key = race_class['_key']\n",
    "\t\trace_class_desc = race_class['name']\n",
    "\n",
    "\t\t# download race results for a race class\n",
    "\t\trider_class_results = url_to_json_dict(base_url+\"race_results/class/\"+race_class_key+\"/1000/0\")\n",
    "\t\trider_class_df = pd.json_normalize(rider_class_results, 'results')\n",
    "\n",
    "\t\t# the ID for riders in each class (used to download specific results)\n",
    "\t\trider_id_list = rider_class_df['rider_id']\n",
    "\n",
    "\t\tstage_class_results = []\n",
    "\t\t\n",
    "\n",
    "\t\tfor rider_id in rider_id_list:\n",
    "\t\t\tindividual_results = url_to_json_dict(f\"{base_url}race_results/rider/{race_class_key}/{rider_id}\")\n",
    "\t\t\tindividual_results = individual_results[0]\n",
    "\n",
    "\t\t\tif len(stage_class_results) == 0:\n",
    "\t\t\t\theader, results = unpack_stage_results(individual_results, rider_id)\n",
    "\t\t\t\tstage_class_results = [header, results]\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\t_, results = unpack_stage_results(individual_results, rider_id)\n",
    "\t\t\t\tstage_class_results.append(results)\n",
    "\n",
    "\t\tstage_class_df = pd.DataFrame(stage_class_results[1:], columns=stage_class_results[0])\n",
    "\n",
    "\t\tfull_rider_results = pd.merge(rider_class_df, stage_class_df, how='left', on='rider_id')\n",
    "\n",
    "\t\t# remove the '_key' column\n",
    "\t\tfull_rider_results.drop('_key', inplace=True, axis=1)\n",
    "\n",
    "\t\t# add in the race class\n",
    "\t\tfull_rider_results.insert(0, 'race_class', value=race_class_desc)\n",
    "\n",
    "\t\t# add in the race name at the beginning of the dataframe\n",
    "\t\tfull_rider_results.insert(0, 'race_name', value=race_name)\n",
    "\n",
    "\t\tresults_dict.update({race_name + \"_\" + race_class_desc : full_rider_results})\n",
    "\n",
    "\t\tfull_rider_results.to_csv(race_name + \"_2022_\" + race_class_desc + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EWS_2022_results = pd.concat([results for race_class, results in results_dict.items() if 'EWS ' in race_class])\n",
    "EWS_2022_results.to_csv('EWS_2022_results_by_race.csv',index=False)\n",
    "\n",
    "# EWSE_2022_results = pd.concat([results for race_class, results in results_dict.items() if 'EWS-E' in race_class])\n",
    "# EWSE_2022_results.to_csv('EWS-E_2022_results_by_race.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of results\n",
    "Now that the data is present in the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95fc6b46201b03e388ee93255aacead15bb4c5a805a1325bd67fb6d36cada86c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
